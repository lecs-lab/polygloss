[config]

mode = lora
pretrained_model = lecslab/polygloss_byt5_2025_09_18

# Dataset
dataset_key = lecslab/polygloss-corpus
glottocode = dido1241
use_translation = true
create_segmentation_to_gloss = train-only
create_transcription_to_gloss = train-test
create_transcription_to_segmentation = train-test

# Training
max_epochs = 50
learning_rate = 1e-4
batch_size = 256
grad_norm=1

lora_rank = 16
lora_alpha = 32
