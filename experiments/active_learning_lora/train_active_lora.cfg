[config]

mode = lora
pretrained_model = lecslab/polygloss-byt5-interleaved-2025-12-28

# Dataset
dataset_key = lecslab/kgv-gloss-polygloss
task_format = interleaved
glottocode = kara1499
# Training
max_epochs = 25
learning_rate = 2e-4
batch_size = 32
grad_norm = 1
optimizer = adamw
lora_rank = 16
lora_alpha = 32
